{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Silver', 'Gold', 'Copper', 'Palladium', 'Platinum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [[[] for split in range(n_fold)] for name in names]\n",
    "\n",
    "for n in range(len(names)):\n",
    "    for split in range(n_fold):\n",
    "        models[n][split] = pickle.load(open(f'{models_dir}/trained_fullmetal_model_id_{names[n]}_fold{str(split)}.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models),len(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = 'train_metals_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 ['Price_Lag_10_Silver', 'log_close/mean_10_Silver', 'log_return_10_Silver', 'Price_Lag_20_Silver', 'log_close/mean_20_Silver', 'log_return_20_Silver', 'Price_Lag_50_Silver', 'log_close/mean_50_Silver', 'log_return_50_Silver', 'mean_close/mean_10_Silver', 'mean_log_returns_10_Silver', 'log_close/mean_10-mean_close/mean_10_Silver', 'log_return_10-mean_log_returns_10_Silver', 'mean_close/mean_20_Silver', 'mean_log_returns_20_Silver', 'log_close/mean_20-mean_close/mean_20_Silver', 'log_return_20-mean_log_returns_20_Silver', 'mean_close/mean_50_Silver', 'mean_log_returns_50_Silver', 'log_close/mean_50-mean_close/mean_50_Silver', 'log_return_50-mean_log_returns_50_Silver', 'Year', 'Month', 'Week_Number', 'Price_Lag_10_Gold', 'log_close/mean_10_Gold', 'log_return_10_Gold', 'Price_Lag_20_Gold', 'log_close/mean_20_Gold', 'log_return_20_Gold', 'Price_Lag_50_Gold', 'log_close/mean_50_Gold', 'log_return_50_Gold', 'mean_close/mean_10_Gold', 'mean_log_returns_10_Gold', 'log_close/mean_10-mean_close/mean_10_Gold', 'log_return_10-mean_log_returns_10_Gold', 'mean_close/mean_20_Gold', 'mean_log_returns_20_Gold', 'log_close/mean_20-mean_close/mean_20_Gold', 'log_return_20-mean_log_returns_20_Gold', 'mean_close/mean_50_Gold', 'mean_log_returns_50_Gold', 'log_close/mean_50-mean_close/mean_50_Gold', 'log_return_50-mean_log_returns_50_Gold', 'Price_Lag_10_Copper', 'log_close/mean_10_Copper', 'log_return_10_Copper', 'Price_Lag_20_Copper', 'log_close/mean_20_Copper', 'log_return_20_Copper', 'Price_Lag_50_Copper', 'log_close/mean_50_Copper', 'log_return_50_Copper', 'mean_close/mean_10_Copper', 'mean_log_returns_10_Copper', 'log_close/mean_10-mean_close/mean_10_Copper', 'log_return_10-mean_log_returns_10_Copper', 'mean_close/mean_20_Copper', 'mean_log_returns_20_Copper', 'log_close/mean_20-mean_close/mean_20_Copper', 'log_return_20-mean_log_returns_20_Copper', 'mean_close/mean_50_Copper', 'mean_log_returns_50_Copper', 'log_close/mean_50-mean_close/mean_50_Copper', 'log_return_50-mean_log_returns_50_Copper', 'Price_Lag_10_Palladium', 'log_close/mean_10_Palladium', 'log_return_10_Palladium', 'Price_Lag_20_Palladium', 'log_close/mean_20_Palladium', 'log_return_20_Palladium', 'Price_Lag_50_Palladium', 'log_close/mean_50_Palladium', 'log_return_50_Palladium', 'mean_close/mean_10_Palladium', 'mean_log_returns_10_Palladium', 'log_close/mean_10-mean_close/mean_10_Palladium', 'log_return_10-mean_log_returns_10_Palladium', 'mean_close/mean_20_Palladium', 'mean_log_returns_20_Palladium', 'log_close/mean_20-mean_close/mean_20_Palladium', 'log_return_20-mean_log_returns_20_Palladium', 'mean_close/mean_50_Palladium', 'mean_log_returns_50_Palladium', 'log_close/mean_50-mean_close/mean_50_Palladium', 'log_return_50-mean_log_returns_50_Palladium', 'Price_Lag_10_Platinum', 'log_close/mean_10_Platinum', 'log_return_10_Platinum', 'Price_Lag_20_Platinum', 'log_close/mean_20_Platinum', 'log_return_20_Platinum', 'Price_Lag_50_Platinum', 'log_close/mean_50_Platinum', 'log_return_50_Platinum', 'mean_close/mean_10_Platinum', 'mean_log_returns_10_Platinum', 'log_close/mean_10-mean_close/mean_10_Platinum', 'log_return_10-mean_log_returns_10_Platinum', 'mean_close/mean_20_Platinum', 'mean_log_returns_20_Platinum', 'log_close/mean_20-mean_close/mean_20_Platinum', 'log_return_20-mean_log_returns_20_Platinum', 'mean_close/mean_50_Platinum', 'mean_log_returns_50_Platinum', 'log_close/mean_50-mean_close/mean_50_Platinum', 'log_return_50-mean_log_returns_50_Platinum']\n"
     ]
    }
   ],
   "source": [
    "#df_train = reduce_mem_usage(df_train)\n",
    "train_merged = df_train.copy()\n",
    "\n",
    "not_use_features_train = ['Date']\n",
    "\n",
    "for name in names:\n",
    "    not_use_features_train.append(f'Price_{name}')\n",
    "\n",
    "features = train_merged.drop(columns=not_use_features_train).columns.to_list()\n",
    "print(len(features), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('O'), dtype('int64')], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2.16 MB\n",
      "Memory usage after optimization is: 0.62 MB\n",
      "Decreased by 71.4%\n"
     ]
    }
   ],
   "source": [
    "train_merged = reduce_mem_usage(train_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_for_infer(df):\n",
    "    df_merged = pd.DataFrame()\n",
    "    df_merged[['timestamp', 'Asset_ID', 'Close']] = 0\n",
    "    for id in range(14):\n",
    "        df_merged = df_merged.merge(df.loc[df[\"Asset_ID\"] == id, ['timestamp', 'Close']].copy(), on=\"timestamp\", how='outer',suffixes=['', \"_\"+str(id)])\n",
    " \n",
    "    df_merged = df_merged.drop(['Asset_ID', 'Close'], axis=1)\n",
    "#     df_merged = df_merged.sort_values('timestamp', ascending=True)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_hist = max(lags)\n",
    "keep_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i, (df_test, df_pred) in enumerate(iter_test):\n",
    "    df_test_merged = merge_infer_2(df_test, one_line)\n",
    "    history_merged = pd.concat([history_merged, df_test_merged])\n",
    "    x_test = get_features(history_merged, train=False)\n",
    "    x_calc = x_test.iloc[-1]\n",
    "    for j , (asset_id,row_id) in enumerate(  zip(   df_test['Asset_ID'].values,  df_test['row_id'].values   )   ): \n",
    "        y_pred_list = []\n",
    "        try:\n",
    "            for split in range(n_fold):\n",
    "                y_pred_list.append(models[ asset_id ][split].predict(x_calc[features]))\n",
    "            y_pred = np.median(y_pred_list)\n",
    "        except Exception:\n",
    "            y_pred = 0\n",
    "        df_pred.loc[  df_pred['row_id'] == row_id ,  'Target'  ] = y_pred\n",
    "\n",
    "    history_merged = history_merged.tail(keep_hist)\n",
    "\n",
    "    env.predict(df_pred)\n",
    "\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
